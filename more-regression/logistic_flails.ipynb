{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93dbbf0d",
   "metadata": {},
   "source": [
    "# Logistic regression can fail with sum of squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec73a373",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a450512",
   "metadata": {},
   "source": [
    "We read in the [mtcars\n",
    "dataset](https://www.rdocumentation.org/packages/datasets/versions/3.6.2/topics/mtcars)\n",
    "that will be very familiar to users of R:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da9177c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtcars = pd.read_csv('mtcars.csv')\n",
    "mtcars.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4b7bca",
   "metadata": {},
   "source": [
    "This dataset has one row per make and model of car.  The columns have various measures and other information about each make and model.\n",
    "\n",
    "The columns we are interested in here are:\n",
    "\n",
    "* `mpg`: Miles/(US) gallon\n",
    "* `am`: Transmission (0 = automatic, 1 = manual)\n",
    "\n",
    "Notice that `am` is already numeric, and so is already a dummy variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3967dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg = mtcars['mpg']\n",
    "am_dummy = mtcars['am']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7891d1b8",
   "metadata": {},
   "source": [
    "We will try to predict whether the car has an automatic transmission (column\n",
    "`am`) using the miles per gallon measure (column `mpg`).\n",
    "\n",
    "Here is a plot of the `am` values against the `mpg` values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef61111",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Code to make nice plots for binary columns.  Please ignore.\n",
    "def plot_binary(df, x_name, bin_name, bin_labels=(0, 1),\n",
    "                color_names=('red', 'blue')):\n",
    "    x_vals = df[x_name]\n",
    "    bin_vals = df[bin_name]\n",
    "    # Build plot, add custom label.\n",
    "    dummy = bin_vals.replace(bin_labels, (0, 1))\n",
    "    colors = bin_vals.replace(bin_labels, color_names)\n",
    "    plt.scatter(x_vals, dummy, c=colors)\n",
    "    plt.xlabel(x_name)\n",
    "    plt.ylabel('%s\\n0 = %s, 1 = %s' % (x_name, bin_labels[0], bin_labels[1]))\n",
    "    plt.yticks([0, 1]);  # Just label 0 and 1 on the y axis.\n",
    "    # Put a custom legend on the plot.  This code is a little obscure.\n",
    "    plt.scatter([], [], c=color_names[0], label=bin_labels[0])\n",
    "    plt.scatter([], [], c=color_names[1], label=bin_labels[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd0ee75",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "plot_binary(mtcars, 'mpg', 'am')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c461aa7c",
   "metadata": {},
   "source": [
    "We need our machinery for calculating the inverse logit transformation,\n",
    "converting from the log-odds-ratio straight line prediction to the sigmoid\n",
    "prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5289a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inv_logit(y):\n",
    "    \"\"\" Reverse logit transformation\n",
    "    \"\"\"\n",
    "    odds_ratios = np.exp(y)  # Reverse the log operation.\n",
    "    return odds_ratios / (odds_ratios + 1)  # Reverse odds ratios operation.\n",
    "\n",
    "\n",
    "def params2pps(intercept, slope, x):\n",
    "    \"\"\" Calculate predicted probabilities of 1 for each observation.\n",
    "    \"\"\"\n",
    "    # Predicted log odds of being in class 1.\n",
    "    predicted_log_odds = intercept + slope * x\n",
    "    return inv_logit(predicted_log_odds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439d277a",
   "metadata": {},
   "source": [
    "This is our simple root mean square cost function comparing the sigmoid p predictions to the 0 / 1 labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4493cddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ss_logit(c_s, x_values, y_values):\n",
    "    # Unpack intercept and slope into values.\n",
    "    intercept, slope = c_s\n",
    "    # Predicted p values on sigmoid\n",
    "    pps = params2pps(intercept, slope, x_values)\n",
    "    # Prediction errors.\n",
    "    sigmoid_error = y_values - pps\n",
    "    # Sum of squared error\n",
    "    return np.sum(sigmoid_error ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3a2c5e",
   "metadata": {},
   "source": [
    "We run minimize using some (it turns out) close-enough initial values for the\n",
    "log-odds intercept and slope:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a6f699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guessed log-odds intercept slope of -5, 0.5\n",
    "mr_ss_ok = minimize(ss_logit, [-5, 0.5], args=(mpg, am_dummy))\n",
    "mr_ss_ok"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6410a0",
   "metadata": {},
   "source": [
    "The prediction sigmoid looks reasonable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb531edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_ok, slope_ok = mr_ss_ok.x\n",
    "predicted_ok = inv_logit(inter_ok + slope_ok * mpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87b3b8e",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "plot_binary(mtcars, 'mpg', 'am')\n",
    "plt.scatter(mpg, predicted_ok, c='gold', label='SS fit, OK start')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3655bc0d",
   "metadata": {},
   "source": [
    "But - if we start with a not-so-close initial guess for the intercept and slope, `minimize` gets terribly lost:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a57e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guessed log-odds intercept slope of 1, 1\n",
    "mr_ss_not_ok = minimize(ss_logit, [1, 1], args=(mpg, am_dummy))\n",
    "mr_ss_not_ok"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07a388b",
   "metadata": {},
   "source": [
    "The prediction sigmoid fails completely:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe0b074",
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_not_ok, slope_not_ok = mr_ss_not_ok.x\n",
    "predicted_not_ok = inv_logit(inter_not_ok + slope_not_ok * mpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f38029",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "plot_binary(mtcars, 'mpg', 'am')\n",
    "plt.scatter(mpg, predicted_not_ok, c='gold', label='SS fit, bad start')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c771690",
   "metadata": {},
   "source": [
    "Can we do better with the maximum likelihood estimate (MLE) cost function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d6e49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit_reg_cost(intercept_and_slope, x, y):\n",
    "    \"\"\" Cost function for maximum likelihood\n",
    "    \"\"\"\n",
    "    intercept, slope = intercept_and_slope\n",
    "    pp1 = params2pps(intercept, slope, x)\n",
    "    p_of_y = y * pp1 + (1 - y) * (1 - pp1)\n",
    "    log_likelihood = np.sum(np.log(p_of_y))\n",
    "    return -log_likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa9e09d",
   "metadata": {},
   "source": [
    "Here we pass some absolutely terrible initial guesses for the intercept and slope:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295c5c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mr_LL = minimize(logit_reg_cost, [10, -5], args=(mpg, am_dummy))\n",
    "mr_LL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e633e8ae",
   "metadata": {},
   "source": [
    "The fit is still reasonable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2f9a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_LL, slope_LL = mr_LL.x\n",
    "predicted_LL = inv_logit(inter_LL + slope_LL * mpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39167a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_binary(mtcars, 'mpg', 'am')\n",
    "plt.scatter(mpg, predicted_LL, c='gold', label='LL prediction')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585c0667",
   "metadata": {},
   "source": [
    "As we have seen before, the MLE fit above is the same algorithm that\n",
    "Statmodels and other packages use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605db51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d872d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smf.logit('am ~ mpg', data=mtcars)\n",
    "fit = model.fit()\n",
    "fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab708609",
   "metadata": {},
   "source": [
    "Notice that the intercept and slope coefficients are the same as the ones we\n",
    "found with the MLE cost function and minimize."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "notebook_metadata_filter": "all,-language_info",
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
